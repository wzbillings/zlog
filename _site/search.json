[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Zane’s Blog (or Zlog for short) is where I plan to post about different things that I’m interested in. Andrew Heiss gave me the excellent advice that all my work should be done in public because you never know what will be useful to someone else, and some of my adviser Andreas Handel’s post have been very helpful to me. So maybe one day my blog will be as useful as their blogs."
  },
  {
    "objectID": "about.html#about-zane",
    "href": "about.html#about-zane",
    "title": "About",
    "section": "About Zane",
    "text": "About Zane\nZane Billings is a PhD student in the data analysis and modeling program, department of epidemiology and biostatistics, University of Georgia, Athens, GA. His main skills are R programming, scientific computing, and statistical data analysis. Most of his research focuses on influenza and the immune response to seasonal influenza vaccines, but he has also done work on norovirus. In general, he is interested in using statistics, data analytics, and modeling methods to improve understand of common viral pathogens."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nUniversity of Georgia | Athens, GA\nPh.D., Epidemiology & Biostatistics | August 2020 - May 2025 (expected)\nWestern Carolina University | Athens, GA\nB.S. in Mathematics and Biology | August 2016 - May 2020"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Zane’s Blog",
    "section": "",
    "text": "When you do multiple diagnostic tests in sequence, how do you estimate your probability of the condition?\n\n\n\n\n\n\nJun 24, 2022\n\n\nZane Billings\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-06-24_Bayes-Diagnostics/index.html",
    "href": "posts/2022-06-24_Bayes-Diagnostics/index.html",
    "title": "Multiple diagnostic testing and Bayes’ rule",
    "section": "",
    "text": "Pic related: this morning a coworker let me know they had tested positive for COVID-19! As someone who actually prefers to go into the office, I knew that this was one of the dangers, so I was at least prepared for this to happen. I grabbed my government-mailed COVID-19 rapid tests from the closet, checked the expiration date, sat down at the table, and…remembered that flu rapid tests have high false positive rates. Admittedly, I know much more about flu diagnostic testing than COVID.\nThe package insert for the Abbott BinaxNOW tests alleges a 91.7% sensitivity (95% CI: 73.0% - 98.9%), but with the 73% lower bound and my skeptical nature, I decided I better go ahead and do two tests. Of course, being a math degree holder, I can certainly work out for myself how to use Bayes’ Rule to update my beliefs about my COVID status after seeing two tests, but I decided to google it to see if there are any quick and easy guides. And of course, most of what I found in the top google results were articles that didn’t really have much content. So, given the advice I’ve recieved from Andreas Handel and Andrew Heiss, I decided to write up my very first blog post about this subject. Finally, a subject where I feel confident enough to write a blog post about it."
  },
  {
    "objectID": "posts/2022-06-24_Bayes-Diagnostics/index.html#diagnostic-test-sensitivity-and-specificity",
    "href": "posts/2022-06-24_Bayes-Diagnostics/index.html#diagnostic-test-sensitivity-and-specificity",
    "title": "Multiple diagnostic testing and Bayes’ rule",
    "section": "Diagnostic test sensitivity and specificity",
    "text": "Diagnostic test sensitivity and specificity\nEvery diagnostic test that produces a dichotomous outcome (for example, COVID-19 positive vs. COVIC-19 negative) has some margin of error. When the test gives you a positive diagnosis, it never means a 100% chance that you are positive. Instead, the test has a probability of being positive, given that you actually have the disease. This probability is called the sensitivity of the test. In math notation, we would write\n\\[\\mathrm{sensitivity} = P\\left(+ \\mid D\\right)\\]\nwhere \\(D\\) is the event that you have the disease (we’ll call the event that you don’t have the disease \\(\\lnot D\\)) and \\(+\\) is the event that you have a positive test (we’ll call the event you have a negative test \\(-\\)). Note that there are only four possibilities with this kind of test.\n\nTrue positive: You actually have the disease, and you test positive.\nFalse positive: You don’t have the disease, but you test positive.\nFalse negative: You actually have the disease, but you test negative.\nTrue negative: You don’t have the disease, and you test negative.\n\nUsing these definitions, the sensitivity of the test is also called the “true positive rate”. Similarly, there is another metric for the test called the specificity, which is called the “true negative rate” and represents the probability that you test negative, given that you do not have the disease. Mathematically, we would write\n\\[\\mathrm{specificity} = P(- \\mid \\lnot D).\\]\nThese quantities are intrinsic to the test. Theoretically, every type of diagnostic test has a true sensitivity and specificity that we can estimate by using the test on people whose disease status we know. In the US, the companies that make these tests are required to do these studies before their products can be approved by the FDA.\nFor the rest of this blog post, we’ll use the slightly more conservative numbers provided in the package insert: in a multi-site clinical study, the test was estimated to have a sensitivity of 85% and a specificity of 99% (rounding to the nearest percentage).\nHowever, the sensitivity and specificity don’t tell us the information that we actually want to know. What I want to know is, given that I tested negative, what is the probability that I do not have COVID-19?"
  },
  {
    "objectID": "posts/2022-06-24_Bayes-Diagnostics/index.html#bayes-rule-and-the-ppvnpv",
    "href": "posts/2022-06-24_Bayes-Diagnostics/index.html#bayes-rule-and-the-ppvnpv",
    "title": "Multiple diagnostic testing and Bayes’ rule",
    "section": "Bayes’ Rule and the PPV/NPV",
    "text": "Bayes’ Rule and the PPV/NPV\nIn math notation, the quantity that we want to calculate is\n\\[P(D \\mid +),\\]\nwhich is sort of the opposite of the sensitivity of the test. Fortunately, statistics has a convenient way to “flip” the conditional probability: Bayes’ Rule.\n\\[P(D \\mid +) = \\frac{P(+ \\mid D)P(D)}{P(+)} = \\frac{\\mathrm{sensitivity} \\cdot \\mathrm{prevalence}}{\\text{probability of testing positive}}\\]\nSo, you see that there are two additional components here that we currently don’t know: the prevalence of the disease, which we call \\(P(D)\\), and the probability of testing positive on the test, \\(P(+)\\).\nWe can use another trick to get \\(P(+)\\) called the law of total probability:\n\\[P(+) = P(+ \\mid D) P(D) + P(+ \\mid \\lnot D) P(\\lnot D).\\]\nUsing some math, we can rewrite this. We know that \\(P(+ \\mid D)\\) is the sensitivity, or true positive rate, so we can rease that \\(P(+ \\mid \\lnot D)\\) is the true negative rate. Additionally, since we either have or don’t have the disease (there is no other outcome), we know that \\(P(\\lnot D) = 1 - P(D)\\), so we get\n\\[P(+) = \\text{TPR} \\cdot P(D) + \\text{FPR} \\cdot (1 - P(D)).\\]\nWe can get the false positive rate from the specificity by noting that, given you have a negative test, you must either have the disease or not (there are only these two options), so then\n\\[1 = P(+ \\mid D) + P(+ \\mid \\lnot D) = \\mathrm{TPR} + \\mathrm{FPR}.\\]\nTherefore, the false positive rate is \\(\\mathrm{TPR} = 1 - 0.99 = 0.01\\). Now we just need to know the prevalence of disease. Of course, I had issues getting the Georgia Department of Public Health’s tracker to work, but when I checked the CDC’s COVID data tracker, there was a reported rate of 150.39 cases per 100,000 population, which works out to a prevalence percentage (cases per 100 people) of 0.15% or 0.0015.\nSo finally we can work out that\n\\[P(+) = (0.85)(0.0015) + (0.01)(0.9985) = 0.00128 + 0.00999 \\approx 0.01270,\\]\nor about \\(1.3\\%\\). (For Athens-Clarke County, Georgia, on June 24, 2022.) Now that we have estimated the probability of a positive test in general, we can compute the value we actually want, which as I mentioned is called the positive predictive value.\nSo, given that we have a positive test, the probability of actually having COVID would be\n\\[\\mathrm{PPV} = P(D \\mid +) = \\frac{P(+ \\mid D)P(D)}{P(+)} = \\frac{0.85\\cdot 0.0015}{0.0127} \\approx 0.1004 = 10.04\\%.\\]\nThat might seem low, but of course your risk of having COVID (your personal \\(P(D)\\)) increases drastically if you’ve been around someone else who tested positive. Later on, I’ll vary this number so we can see this effect in action.\nConversely, since you’ve already seen that I tested negative, we might want the negative predictive value: the probability of actually being negative, given that the test was negative. We compute this similarly, so I won’t walk through all the steps this time. We have\n\\[\\mathrm{NPV} = P(\\lnot D \\mid -) = \\frac{P(- \\mid \\lnot D)P(\\lnot D)}{P(-)} = \\frac{P(- \\mid \\lnot D)P(\\lnot D)}{P(- \\mid \\lnot D)P(\\lnot D) + P(- \\mid D)P(D)},\\]\nwhich works out mathematically in the same way as the PPV, and we get\n\\[\\mathrm{NPV} = \\frac{0.99 \\cdot 0.9985}{(0.99 \\cdot 0.9985) + (0.15\\cdot0.0015)} \\approx 0.9998 \\approx 99.8\\%.\\]\nAgain, remember that this is heavily dependent on what we chose as the prevalence."
  },
  {
    "objectID": "posts/2022-06-24_Bayes-Diagnostics/index.html#last-updated",
    "href": "posts/2022-06-24_Bayes-Diagnostics/index.html#last-updated",
    "title": "Multiple diagnostic testing and Bayes’ rule",
    "section": "Last updated",
    "text": "Last updated\n\n2022-06-24 12:50:12 EDT"
  },
  {
    "objectID": "posts/2022-06-24_Bayes-Diagnostics/index.html#details",
    "href": "posts/2022-06-24_Bayes-Diagnostics/index.html#details",
    "title": "Multiple diagnostic testing and Bayes’ rule",
    "section": "Details",
    "text": "Details\n\nsource code\n\nsessionInfo()\n\nR version 4.1.2 (2021-11-01)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19044)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=English_United States.1252 \n[2] LC_CTYPE=English_United States.1252   \n[3] LC_MONETARY=English_United States.1252\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.1252    \n\nattached base packages:\n[1] stats     graphics  grDevices datasets  utils     methods   base     \n\nother attached packages:\n[1] ggplot2_3.3.6 dplyr_1.0.9  \n\nloaded via a namespace (and not attached):\n [1] pillar_1.7.0     compiler_4.1.2   tools_4.1.2      digest_0.6.29   \n [5] jsonlite_1.8.0   evaluate_0.15    lifecycle_1.0.1  tibble_3.1.7    \n [9] gtable_0.3.0     pkgconfig_2.0.3  rlang_1.0.2      cli_3.3.0       \n[13] rstudioapi_0.13  yaml_2.3.5       xfun_0.31        fastmap_1.1.0   \n[17] withr_2.5.0      stringr_1.4.0    knitr_1.39       generics_0.1.2  \n[21] vctrs_0.4.1      grid_4.1.2       tidyselect_1.1.2 glue_1.6.2      \n[25] R6_2.5.1         fansi_1.0.3      rmarkdown_2.14   farver_2.1.0    \n[29] purrr_0.3.4      magrittr_2.0.3   scales_1.2.0     ellipsis_0.3.2  \n[33] htmltools_0.5.2  colorspace_2.0-3 renv_0.15.5      labeling_0.4.2  \n[37] utf8_1.2.2       stringi_1.7.6    munsell_0.5.0    crayon_1.5.1"
  }
]